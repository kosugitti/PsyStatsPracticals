# 統計的仮説検定(Null Hypothesis Statistical Testing)

帰無仮説検定は，心理学における統計の利用シーンの代表的なものだろう。
その手順は形式化されており，統計パッケージによってはデータの種類を指定するだけで自動的に結果の記述までしてくれるものもあるほどである。誰がやっても同じ結果になり，また，機械的に手続きを自動化できることは大きな利点ではある。欠点は，初学者がそのメカニズムを十分に理解せずに誤った結果を得たり，悪意のある利用者が自分に都合の良い数字を出させたりすることにある。科学的営みは悪意をもった実践者を想定しておらず，もしそのような悪例が露見した場合には事後的に摘発・対処するしかない。しかし残念なことながら，初学者の浅慮や意図せぬ悪用も多くみられる。

心理学において，先行研究の結果が再現しないことを再現性問題というが，そのひとつは統計的手法の誤った使い方にあるとされる[@Ikeda2016]。改めて，丁寧に帰無仮説検定の手続きやロジックを見ていくことにしよう。

## 帰無仮説検定の理屈と手続き

### 帰無仮説検定の目的

帰無仮説検定は，実験や調査で得たデータから得られた知見が意味のあるものかどうか，母集団の性質として一般化可能かどうかを判定するための枠組みである。手法と判断基準が明確なゲームの一種だと考えたよう。というのも，帰無仮説検定は**有意水準**という基準を設けて，**帰無仮説**と**対立仮説**という2つの考え方(モデル)を対決させ，勝敗を決するものだからである。勝敗を決するとしたのは，帰無仮説と対立仮説は排他的な関係にあるからであり，どちらも正しいとかどちらも間違っているという結末にはならないからである。ただし，あくまでも推測統計的なロジックに基づく判定であるから，判定結果にも確率的な要素が含まれる。本当は帰無仮説が正しい時に，間違って「対立仮説が正しい」と判定してしまう確率はゼロではない。逆に帰無仮説が正しくない時に，間違って「対立仮説が正しくない(帰無仮説が正しい)」と判定してしまう可能性もある。前者を**タイプ1エラー**，後者を**タイプ2エラー**という。どちらの確率もゼロであってほしいが，そうはならないので，前者を$\alpha$，後者を$\beta$としたときに，それぞれを一定の水準以下に抑えたい。この目的のために手順を整え，一般化したのが帰無仮説検定である。なお，先に述べた有意水準は，この$\alpha$の許容される水準であり，心理学では一般に5%に設定する。

このように帰無仮説検定という考え方は，エラーの統制が本来の狙いであるから，「有意になるように工夫する」という発想は根本的に間違っている。また，統計的推定という数学的手続きに，人間が納得しやすい判定を下すという人為的手続きが組み合わさったものであるから，帰無仮説検定の結果に過剰な意味を持たせたり一喜一憂したりすることがないように注意しよう。

### 帰無仮説検定の手続き

帰無仮説検定の手続きを一般化すれば，次のようになる。

1. 帰無仮説と対立仮説を設定する。
2. 検定統計量を選択する。
3. 判定基準を決定する。
4. 検定統計量を計算する。
5. 判定する。

帰無仮説検定は，群間の平均値に差があるかどうか，相関係数に統計的な意味があるかどうかといった事例に対して適用される。
当然のことながら，これは標本から母集団を推定するという文脈における話で，物理学的な真偽を理論的に判断するとか，全数調査のように母集団全体の情報が手に入る場合といった場合の話ではない。また，標本のサンプルサイズが小さく，標本統計量の信頼区間が大きいことから，枠組みなしには判定できないという背景があることも再確認しておこう。

母集団の状態がわからないので，仮説を設定する。帰無仮説Null Hypothesisは空っぽの仮説という意味で，母平均差がない(差がゼロ，$\mu_1 - \mu_2 = 0$)とか，母相関がゼロ($\rho = 0$)である，とされる。対立仮説Alternative Hypothesisは帰無仮説と排他的な関係にある仮説としてつくられるから，「差が無くはない($\mu_1 - \mu_2 \neq 0$)」「相関がゼロではない($\rho \neq 0$)」という表現になる。なぜ帰無仮説がゼロであることから始められるかといえば，ふたつの排他的な仮説を考えた時にゼロでない状態というのは無数にあり得るので，仮説として特定できないからである(差が1のとき，1.1のとき，1.11のとき・・・と延々と検定し続けるわけにもいくまい)。

検定統計量の選択は，二群の平均値差のときは$t$，三群以上の時は$F$，相関係数の検定も$t$，と天下り的に示されることが一般的である。もちろんこれらの統計量が選ばれるのは，数理統計的な論拠に基づいている。判定基準は5%水準とすることが一般的だし，検定統計量の計算はアルゴリズムに沿って機械的に可能である。判定は客観的な指標に基づいて行われるから，「どの状況でどのような帰無仮説をおくか」が類型化できれば，この手続き全体が自動的に進められる。

しかしここでは改めて，丁寧に手順を追いながらみてみよう。

## 相関係数の検定

ここでは相関係数の検定を例に取り上げる。俗に「無相関検定」と呼ばれるように，相関がどれほど大きいとかどれほど意味があるということをチェックするのでは無く，無相関ではない，ということをチェックする。もちろん標本相関は計算してゼロでなければ，それは無相関ではない。ここで考えたいのは，母相関がゼロではないということである。言い換えると，母相関がゼロの状態であっても，標本相関がゼロでないことは，小標本のサンプリングという背景のもとでは当然のことである。

確認してみよう。まず，無相関なデータセットを作ることを考える。Rの`MASS`パッケージを使い，多変量正規分布の確率分布関数から乱数を生成しよう。

```{r,zeroR}
library(MASS)
set.seed(12345)
N <- 100000
X <- mvrnorm(N, mu = c(0,0), 
            Sigma = matrix(c(1,0,0,1),ncol = 2),
            empirical = TRUE)
head(X)
```

ここでは`r N`個の乱数を生成した。つくられたオブジェクト`X`は表示されているように，2変数からなる。ここでは相関のある2変数を想定しており，各変数がそれぞれ標準正規分布に従っているという設定である。`rnorm`関数を2つ使って2変数をつくっても良いのだが，2変数セットで取り出すことを考えると多変量正規分布をかんがえることになる。多変量正規分布は，ひとつひとつの変数については正規分布として平均とSDをもち，かつ，変数の組み合わせとして共分散をもつものである。`mvrnorm`の引数をみると，`mu`は平均ベクトルであり，`Sigma`が分散共分散行列である。分散共分散行列とは，ここでは$2\times 2$の正方行列であり，対角項に分散を，対角項に共分散をもつ行列である。共分散は標準偏差と相関係数の積で表される。

**分散**

$$ s_x^2 = \frac{1}{n}\sum (x_i - \bar{x})^2 =  \frac{1}{n}\sum (x_i - \bar{x})(x_i - \bar{x})$$

**標準偏差**

$$ s_x = \sqrt{s_x^2} = \sqrt{\frac{1}{n}\sum (x_i - \bar{x})^2}$$

**共分散**

$$ s_{xy} = \frac{1}{n}\sum (x_i - \bar{x})(y_i - \bar{y})$$

**相関係数**

$$r_{xy} = \frac{s_{xy}}{s_xs_y} = \frac{\frac{1}{n}\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\frac{1}{n}\sum (x_i - \bar{x})^2}\sqrt{\frac{1}{n}\sum (y_i - \bar{y})^2}}$$


**分散共分散行列**

$$\Sigma = \begin{pmatrix} s_x^2 & s_{xy} \\ s_{yx} & s_y^2 \end{pmatrix}
= \begin{pmatrix} s_x^2 & r_{xy}s_xs_y \\ r_{xy}s_xs_y & s_y^2 \end{pmatrix}$$

今回`Sigma = matrix(c(1,0,0,1),ncol = 2)`としたのは，この2変数が無相関であること(SDはそれぞれ1であること)を指定している。ちなみに`empirical = TRUE`のオプションは，生成された乱数が設定した分散共分散行列のもつ相関係数と一致するように補正することを意味している。

可視化しておこう。つくられた乱数が無相関であることを，散布図を使って確認する。

```{r,ggR}
#| fig.height: 5
#| fig.width: 5
#| dev: "ragg_png"
library(tidyverse)
X  %>% 
as.data.frame() %>% 
ggplot(aes(x=V1,y=V2))+geom_point()
```

数値的にも確認しておこう。

```{r,corr}
cor(X) %>% round(5)
```

つくられた乱数が無相関であることが確認できた。さてこれが母集団であったとして，ここからたとえば`n = 20`のサンプルをとったとする。この時の相関はどうなるだろうか。
Rで計算してみよう。`sample`関数をつかって抜き出す行を決めて，該当する行だけ`s1`オブジェクトに代入する。その上で相関係数を計算してみよう。

```{r samp1}
selected_row <- sample(1:N,20)
print(selected_row)

s1 <- X[selected_row,]
cor(s1)
```

今回の相関係数は`r cor(s1)[1,2]`となった。母集団の相関係数が0であっても，適当に抜き出した20点が相関係数を持ってしまう(0でない)ことはあり得ることなのである。問題は，これがどの程度あり得ることなのか，である。いいかえると，研究者が`n=20`のサンプルをとって相関を得た時，それが`r = 0.14`であったとしても，母相関$\rho = 0.0$からのサンプルである可能性がどれぐらいあるか，ということである。

## 標本相関係数の分布
## 2種類の検定のエラー確率

