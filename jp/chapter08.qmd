# 平均値差の検定

平均値差の検定は，実験計画の結論を出すために用いられる手段である。無作為割り当てによって個人差や背景要因が相殺され，平均的な因果効果を検証することができるからである。
その結果を一般化するためには，やはり推測統計学の知見が必要であり，サンプルサイズやタイプ1,2エラーが関わってくることに変わりはない。

## 一標本検定

まず配置標本検定の例から始める。母平均がわかっている，あるいは理論的に仮定される特定の値に対して，標本平均が統計的に有意に異なっていると言って良いかどうかの判断をするときに用いる。
たとえば7件法のデータを取ったときに，ある項目の平均が中点4より有意に離れていると言って良いかどうか，といった判定をするときに用いる。かりに，サンプルサイズ10で7件法のデータが得られたとしよう。ここでは平均4,SD1の正規乱数を10件生成することで表現する。実際にはこの値を，人に対する尺度カテゴリへの反応として得ているはずである。

```{r,oneTsample}
library(tidyverse)
set.seed(17)
n <- 10
mu <- 4
X <- rnorm(n, mean = mu, sd = 1)
print(X)
```

今回，標本平均は`r round(mean(X),3)`であり，これより極端な値が$\mu = 4$の母集団から得られるかどうかを検定する。帰無仮説検定の手順にそって進めていくと，以下のようになる。

1. 帰無仮説は母平均が理論的な値(ここでは尺度の中点4)であること，すなわち$\mu =4$であり，対立仮説は$\mu \neq 4$ である。
2. 検定統計量は，正規母集団から得られる標本平均が従う標本分布であり，母分散が未知の場合の区間推定に用いたT統計量になる。
3. 判断基準は心理学の慣例に沿って5%とする。

このあと，検定統計量の計算と判定である。これをRは`t.test`関数で一気に処理できる。

```{r,Os.ttest}
result <- t.test(X, mu = mu)
print(result)
```

結果として，今回の検定統計量の実現値は`r round(result$statistic,3)`であり，自由度`r result$parameter`のt分布からこれ以上の値が出てくる確率は，`r round(result$p.value,3)`であることがわかる。これは5%水準と見比べてより大きいので，レアケースではないと判断できる。つまり，母平均4の正規母集団から，`r round(mean(X),3)`の標本平均が得られることはそれほど珍しいものではなく，統計的に有意に異なっていると判断するには及ばない，ということである。

レポートなどに記載するときは，これら実現値やp値を踏まえて「$t(9)=0.66776,p=0.5151 ,n.s.$」などとする。ここでn.s.はnot significantの略である。

さてこの例では，母平均4の正規乱数を生成し，その平均が4と異なるとはいえない，と結論づけた。これは一見，当たり前のことのようであり，無意味な行為におもえるかもしれない。しかし次の例を見てみよう。

```{r,Os.ttest2}
n <- 3
mu <- 4
X <- rnorm(n, mean = mu, sd = 1)
mean(X) %>%
  round(3) %>%
  print()
result <- t.test(X, mu = mu)
print(result)
```

ここではサンプルサイズ$n=3$であり，標本平均が`r round(mean(X),3)`であった。このときt値は5%臨界値を上回っており，「母平均4のところから得られる値にしては極端」であるから，統計的に有意に異なる，と判断することになる。乱数生成時は平均を確かに4に設定したが，母平均から取り出したごく一部が，そこから大きく離れてしまうことはあり得るのである。

## 二標本検定

続いて二標本の検定について考えよう。実験群と統制群のように，無作為割り当てをすることで平均因果効果をみる際に行われるのが，この検定である。帰無仮説は「群間差はない」であり，対立仮説はその否定である。また，正規母集団からの標本を仮定するので，検定統計量はここでもt分布に従う値になる。帰無仮説検定の手順に沿って，改めて確認しておこう。

1. 帰無仮説は「二群の母平均に差がない」である。二群の母平均をそれぞれ$\mu_1,\mu_2$とすると，帰無仮説は$\mu_1 = \mu_2$，あるいは$\mu_1 - \mu_2 = 0$と表される。対立仮説は$\mu_1 \neq \mu_2$あるいは$\mu_1-\mu_2 \neq 0$である。
2. 検定統計量は，正規母集団から得られる標本平均が従う標本分布であり，母分散が未知の場合の区間推定に用いたT統計量になる。
3. 判断基準は心理学の慣例に沿って5%とする。

これを検証するために，サンプルデータを乱数で生成しよう。
まず，各群のサンプルサイズを`n1,n2`とする。ここでは話を簡単にするため，サンプルサイズは両群ともに`10`とした。つぎに両群の母平均だが，群1の母平均を$\mu_1$，群2の母平均を$\mu_2 = \mu_1 + d$で表現した。この`d`は差分であり，これが$d=0$であれば母平均が等しいこと，$d \neq 0$であれば母平均が異なることになる。最後に両群の母SDを設定した。

ここでの検定は，この差分$d$が母平均0の母集団から得られたと判断して良いかどうか，という形で行われる。検定統計量$T$は，次式で算出されるものである。

$$ T = \frac{d - \mu_0}{\sqrt{U^2_p/\frac{n_1n_2}{n_1+n_2}}}$$

ここで$U^2_p$はプールされた不偏分散と呼ばれ，二群を合わせて計算された全体の母分散推定量である。各群の標本分散をそれぞれ$S^2_1, S^2_2$とすると，次式で算出される。

$$ U^2_p = \frac{n_1S^2_1+ n_2S^2_2}{n_1 + n_2 -2} $$

これらの式はつまり，サンプルサイズの違いを考慮するため，一旦両群の標本分散に各サンプルサイズを掛け合わせ，プールした全体のサンプルサイズから各々$-1$をすることで全体として不偏分散にしている。

これを踏まえて，具体的な数字で見ていこう。
その上で乱数でデータを生成し，その標本平均を確認した上で，`t.test`関数によって検定を行っている。

```{r,Ts.ttest}
n1 <- 10
n2 <- 10
mu1 <- 4
sigma <- 1
d <- 1
mu2 <- mu1 + (sigma * d)

set.seed(42)
X1 <- rnorm(n1, mean = mu1, sd = sigma)
X2 <- rnorm(n2, mean = mu2, sd = sigma)

X1 %>%
  mean() %>%
  round(3) %>%
  print()
X2 %>%
  mean() %>%
  round(3) %>%
  print()

result <- t.test(X1, X2, var.equal = TRUE)
print(result)
```

今回の母平均は$\mu_1 = 4, \mu_2 = 4+1$にしているが，標本平均は`r round(mean(X1),3)`と`r round(mean(X2),3)`であり，標本上では大きな差が見られなかった。結果として，t値は`r abs(result$statistic)`であり，自由度`r result$parameter`のもとでのp値は`r result$p.value`である。5%水準を上回る値であるから，結論としては対立仮説を採択するには至らない，差があるとはいえない，である。

今回の設定では母平均に差があるはず($4 \neq 4 + 1$)なのだから，これは誤った判断で，タイプ2エラーが生じているケースということになる。研究実践場面では，母平均やその差については知り得ないのだから，このような判断ミスが生じていたかどうかは分かり得ないことに留意しよう。

なお，ここではわかりやすく2群であることを示すために`X1`,`X2`と2つのオブジェクトを用意したが，実践的にはデータフレームの中で群わけを示す変数があり，`formula`の形で次のように書くことが多いだろう。

```{r}
dataSet <- data.frame(group = c(rep(1,n1),rep(2,n2)), value = c(X1,X2)) %>% 
    mutate(group = as.factor(group))
t.test(value ~ group, data = dataSet, var.equal = TRUE)
```


## 二標本検定(ウェルチの補正)

先ほどのt.test関数には，`var.equal = TRUE`というオプションが追加されていた。これは2群の分散が等しいと仮定した場合の検定になる。t検定は歴史的にこちらが先に登場しているが，2群の分散が等しいかどうかはいきなり前提できるものでもない。等分散性の検定は，Levene検定を行うのが一般的であり，R においては，`car`パッケージや`lawstat` パッケージが対応する関数を持っている。ここでは`car`パッケージの `leveneTest`関数を用いる例を示す。

```{r}
library(car)
leveneTest(value ~ group, data = dataSet, center = mean)
```

この結果を見ると，p値から明らかなように，2群の分散が等しいという帰無仮説が棄却**できなかった**ので，等しいと考えてt検定に進むことができる。もしこれが棄却されてしまったら，2群の分散が等しいという帰無仮説が成り立たないのだから，等分散性の仮定を外す必要がある。実行は簡単で，`var.equal`を`FALSE`にすれば良い。

```{r}
result2 <- t.test(value ~ group, data = dataSet, var.equal = FALSE)
print(result2)
```
よく見ると，タイトルがWelch Two Sample t-testに変わっている。Welchの補正が入ったt検定という意味である。また自由度が実数(`r round(result2$parameter,3)`)になっているが，このようにt分布の自由度を調整することで等分散性の仮定から逸脱した場合の補正となる。もちろん報告する際は「$t($ `r round(result2$parameter,3)` $)=$ `r round(result2$statistic,3)`, $p=$ `r round(result2$p.value,3) `」のように書くことになるから，自由度が実数であれば補正済みであると考えられるだろう。

しかし，分散が等しいという仮定は，等しくない場合の特殊な場合であるから，最初からWelchの補正がはいった検定だけで十分である。このような考え方から，Rにおける`t.test` 関数のデフォルトでは`var.equal = FALSE`となっており，特段の指定をしなければ等分散性の仮定をしない。こちらの方が検定を重ねることがないので，より望ましい。

### 効果量の算出

今回の例は，仮想データとして$\mu_1 = 4,\mu_2 = mu_1 + \sigma d$であり，明らかに$\mu_1 \neq \mu_2$なのだが，有意差を検出するには至らなかった。統計的な有意差はあくまでも「統計的な」観点からのものであり，我々が現実に検証したいのは本当に差があるかどうか，いわば「実質的な差」があるかどうかであるのだから，統計的な有意差を得ることを目的にするのははっきりと不適切な目標設定であると言えるだろう[^8.1]。

[^8.1]: たとえば物理学などのシーンでは，測定の精度が高く，単一の物理世界を対象にした検証を行うのだから，予測が真であるか偽であるかを確率的に考えるような必要はない。そのような世界における検証--あえて理論的な正しさが明確な世界，と表現するが--であれば，統計的な差があるかどうかの情報はあくまでも理論を支持するおまけ情報にすぎない。いわば統計的検定の結果を報告するのは，論文を書くためのレトリックである。翻って，人間を対象にした小サンプルの科学である心理学は，統計的な判断に頼らざるを得ないという側面はあるだろう。しかしだからと言って，実質的な差が本質的であることを忘れてしまっては本末転倒である。

ところで，統計的に差があるとはっきり言えるのはどのような時だろうか。これは次の4つのデータの分布を見てもらうとわかりやすい。


```{r}
#| echo: FALSE
#| message: FALSE
library(tidyverse)
library(ggplot2)
library(gridExtra)
dL <- 2
dS <- 0.2
sL <- 2
sS <- 0.2

g1 <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
    stat_function(fun = dnorm,args=list(mean=dL,sd=sS),color="red") +
    stat_function(fun = dnorm,args=list(mean=-dL,sd=sS),color="blue") +
    xlab("")+ylab("")+theme(axis.text.y=element_blank())
g2 <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
    stat_function(fun = dnorm,args=list(mean=dS,sd=sS),color="red") +
    stat_function(fun = dnorm,args=list(mean=-dS,sd=sS),color="blue") +
    xlab("")+ylab("")+theme(axis.text.y=element_blank())
g3 <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
    stat_function(fun = dnorm,args=list(mean=dL,sd=sL),color="red") +
    stat_function(fun = dnorm,args=list(mean=-dL,sd=sL),color="blue") +
    xlab("")+ylab("")+theme(axis.text.y=element_blank())
g4 <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
    stat_function(fun = dnorm,args=list(mean=dS,sd=sL),color="red") +
    stat_function(fun = dnorm,args=list(mean=-dS,sd=sL),color="blue") +
    xlab("")+ylab("")+theme(axis.text.y=element_blank())
g <- grid.arrange(g1,g2,g3,g4)
```

左列は平均差が大きいデータ，右列は小さいデータである。
上段は分散が小さいデータ，下段は大きいデータである。
この4つそれぞれのシーンにおいて，「差がある」と判断しやすいのはどれかを考えてみるとよい。当然，左上のシーンが最も明確に差があると言えるであろう。なぜなら，両群が明確に分かれており，群間の重複がないからである。左下は同じ平均値差であっても，群内の広がりが大きいから群間の重複がみられるため，「差がある」という判断を受けても各群の中には該当しないケースがちらほらみられることだろう。右上パネルのようなケースでは，重複は少ないが差が小さいため，「差がある」と判断できるかどうかが微妙である。右下に至っては，差も小さく分布の重複も大きいから，「差がある」と判断しても該当しないケースが多くなる。たとえば「男性は女性よりも力が強い(体力・筋力に差がある)」というデータがあったとしても，「女性より非力な男性」もかなり多く存在するだろう。そういう反例が多くみられるような場合，統計的に差があるという結果が示されたとしても，受け入れられないのではないだろうか。

ここから明らかなように，差の判断には平均値差だけでなく分散も関わってくる。そこで平均値差を標準偏差で割った，**標準化された差**が重要になってくるのであり，これが**効果量**と呼ばれるものである[^8.2]。

[^8.2]: 統計的な有意差よりも効果量，効果量よりも実質的な差のほうが意味のある差であることを忘れてはならない。詳しくは @Toyoda2009 を参照。

今回2群の差のデータを作る時に，$\sigma d$ としたが，平均値差の効果量esは，
$$ es = \frac{\mu_1 - \mu_2}{\sigma} $$

で表現されるから，$d$が効果量を表していたのである。もちろん我々は母平均，母SDなどを知り得ないのでこれもデータから推定する他ない。幸いRには`effsize`パッケージなど，効果量を算出するものが用意されている。

```{r}
library(effsize)
cohen.d(value ~ group, data = dataSet)
cohen.d(value ~ group, data = dataSet, hedges.correction =TRUE)
```

平均値差の検定の後は，ここに示したCohenのdやHedgesのgといった効果量を添えて報告することが一般的である。

## 対応のある二標本検定

## レポートを書くような課題

